{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI\n",
    "\n",
    "> Contains all the CLI functions that your library provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data and code taken from https://github.com/github/CodeSearchNet\n",
    "\n",
    "```\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 GitHub\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "```\n",
    "\n",
    "```\n",
    "@article{husain2019codesearchnet,\n",
    "  title={{CodeSearchNet} challenge: Evaluating the state of semantic code search},\n",
    "  author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
    "  journal={arXiv preprint arXiv:1909.09436},\n",
    "  year={2019}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastcore.script import call_parse, Param\n",
    "from icodegen.data.core import (\n",
    "    _download_data,\n",
    "    process_data,\n",
    ")\n",
    "from icodegen.model.core import (\n",
    "    VANILLA_CONFIG,\n",
    "    GRU_CONFIG_1,\n",
    "    GRU_CONFIG_2,\n",
    "    GRU_CONFIG_3,\n",
    "    GRU_CONFIG_4,\n",
    "    GRU_CONFIG_5,\n",
    "    train,\n",
    ")\n",
    "from icodegen.evaluation.core import evaluate\n",
    "from pathlib import Path\n",
    "\n",
    "seed = 115\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def download_data(\n",
    "    out_path: Param(\"The output path to download and extract all files to.\", str)\n",
    "):\n",
    "    \"\"\"\n",
    "    Function for downloading all the data to reproduce our study.\n",
    "    \"\"\"\n",
    "    out_path = Path(out_path)\n",
    "\n",
    "    _download_data(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/tmp/data\")\n",
    "download_data(str(data_path))\n",
    "\n",
    "bigclone_path = data_path / \"bigclonebenchmark\"\n",
    "assert Path(bigclone_path / \"bigclonebenchmark_lg.csv\").exists()\n",
    "assert Path(bigclone_path / \"bigclonebenchmark_sm.csv\").exists()\n",
    "\n",
    "bugfix_path = data_path / \"bug_fix\"\n",
    "assert Path(bugfix_path / \"bug_fix_pairs.zip\").exists()\n",
    "assert Path(bugfix_path / \"50-100/buggy\").exists()\n",
    "assert Path(bugfix_path / \"50-100/fixed\").exists()\n",
    "\n",
    "codesearchnet_path = data_path / \"codesearchnet\"\n",
    "assert Path(codesearchnet_path / \"codesearchnet_java\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Hyperparams for reproduction\n",
    "EPOCHs = 100\n",
    "MAX_LEN = 256\n",
    "BS = 64\n",
    "\n",
    "_RNN_CONFIGs = [\n",
    "    VANILLA_CONFIG,\n",
    "    GRU_CONFIG_1,\n",
    "    GRU_CONFIG_2,\n",
    "    GRU_CONFIG_3,\n",
    "    GRU_CONFIG_4,\n",
    "    GRU_CONFIG_5,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def reproduce(\n",
    "    out_path: Param(\n",
    "        \"The output directory to download, extract, and save all files to.\", str\n",
    "    ),\n",
    "    n: Param(\"Number of examples to train on for testing purposes.\", int) = None,\n",
    "):\n",
    "    \"\"\"Function for reproducing results related to the library.\"\"\"\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    out_path = Path(out_path)\n",
    "    data_path = out_path / \"data\"\n",
    "\n",
    "    _download_data(data_path)\n",
    "    process_data(data_path)\n",
    "\n",
    "    trn_data_path = data_path / \"codesearchnet\"\n",
    "    models_path = out_path / \"models\"\n",
    "    train(\n",
    "        data_path=trn_data_path,\n",
    "        out_path=models_path,\n",
    "        epochs=EPOCHs,\n",
    "        max_length=MAX_LEN,\n",
    "        batch_size=BS,\n",
    "        configs=_RNN_CONFIGs,\n",
    "        n=n,\n",
    "    )\n",
    "\n",
    "    evaluate(data_path, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading BigCloneBenchmark datasets.\n",
      "INFO:root:Downloading and extracting Bug Fix Pairs dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /tmp/output/data/bigclonebenchmark/bigclonebenchmark.zip\n",
      "File exists: /tmp/output/data/bug_fix/bug_fix_pairs.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading and extracting CodeSearchNet Challenge dataset.\n",
      "INFO:root:File exists: /tmp/output/data/codesearchnet\n",
      "INFO:root:Training new tokenizer and saving to /tmp/output/models/tokenizer.json.\n",
      "INFO:root:Starting the training of all RNN based models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6/6 [==============================] - 2s 303ms/step - loss: 7.8663 - val_loss: 6.1201\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 1s 223ms/step - loss: 6.0533 - val_loss: 6.1887\n",
      "INFO:tensorflow:Assets written to: /tmp/output/models/rnn_layers1_vocab3798_embed256_units1024/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/output/models/rnn_layers1_vocab3798_embed256_units1024/assets\n",
      "INFO:root:Starting the training of all Transformer based models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/output/models/rnn_layers1_vocab3798_embed256_units1024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4af1ec7f3b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_RNN_CONFIGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mVANILLA_CONFIG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mreproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8ea08ba9642c>\u001b[0m in \u001b[0;36mreproduce\u001b[0;34m(out_path, n)\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/icodegen/evaluation/core.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_path, model_path)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Long-Range Interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         results[m_path.name][\"long_range\"] = _long_range(\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mbigclone_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbugfix_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodesearchnet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         )\n",
      "\u001b[0;32m~/work/icodegen/evaluation/core.py\u001b[0m in \u001b[0;36m_long_range\u001b[0;34m(bigclone_path, bugfix_path, codesearchnet_path, model, n)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     ]\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0mlong_range_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"buggy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_buggy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     df_fixed = pd.read_json(bugfix_path / \"fixed.jsonl\", orient=\"records\", lines=True)[\n",
      "\u001b[0;32m~/work/icodegen/evaluation/core.py\u001b[0m in \u001b[0;36m_get_metrics\u001b[0;34m(df, model)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mmean_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0mdf_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_dist_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmean_cross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/icodegen/evaluation/core.py\u001b[0m in \u001b[0;36mget_mean_probs\u001b[0;34m(df, model, n)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# setup container lists for the number of occurrences and sum of probabilities for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0msum_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# loop through each method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "OUT_PATH = \"/tmp/output\"\n",
    "N = 100\n",
    "EPOCHs = 2\n",
    "MAX_LEN = 32\n",
    "BS = 16\n",
    "_RNN_CONFIGs = [VANILLA_CONFIG]\n",
    "\n",
    "reproduce(OUT_PATH, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.core.ipynb.\n",
      "Converted 01_data.transforms.ipynb.\n",
      "Converted 02_model.core.ipynb.\n",
      "Converted 04_evaluation.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
